# Deployment Guide

This guide covers deploying mail-done to a self-hosted server using Docker or Podman.

> **Related Documentation:**
> - [Email Processing](PROCESS_INBOX.md) - Process and classify emails
> - [MCP Server](MCP.md) - Integrate with Claude, Cursor
> - [API Reference](API.md) - REST API endpoints
> - [Database Schema](DATABASE.md) - PostgreSQL structure
> - [Gmail Setup](GMAIL_SETUP.md) - App Passwords for Gmail/Google Workspace
> - [Outlook OAuth2](OUTLOOK_OAUTH2.md) - Microsoft 365 authentication
> - [LLM Configuration](LLM_CONFIGURATION.md) - Multi-provider AI setup

## Hardware Requirements

mail-done is designed to run on modest hardware, including single-board computers like the Raspberry Pi.

### Minimum Requirements

| Component | Minimum | Recommended | Notes |
|-----------|---------|-------------|-------|
| **RAM** | 2GB | 4GB+ | PostgreSQL benefits from more RAM for caching |
| **Storage** | 16GB | 32GB+ | Database grows ~1MB per 1000 emails |
| **CPU** | ARMv8 / x86-64 | 4+ cores | Container builds are CPU-intensive |

### Storage Considerations

**SSD or NVMe strongly recommended over SD cards:**

| Storage Type | Build Time | Database Performance | Reliability |
|--------------|------------|---------------------|-------------|
| **NVMe/SSD** | Fast (seconds) | Excellent | High |
| **USB SSD** | Fast | Good | Good |
| **SD Card** | Slow (minutes) | Marginal | Limited write cycles |
| **HDD** | Moderate | Good | Good |

For Raspberry Pi deployments:
- **USB SSD** is the sweet spot: affordable, fast, reliable
- **SD cards** work but are significantly slower and have limited write endurance
- Vector similarity search and embedding generation benefit greatly from fast storage
- Database writes (email processing) can wear out SD cards over time

### Tested Platforms

| Platform | Status | Notes |
|----------|--------|-------|
| **Raspberry Pi 4 (4GB)** | Fully supported | Production-tested, USB SSD recommended |
| **Raspberry Pi 5** | Supported | Better performance, NVMe via HAT recommended |
| **x86-64 Linux** | Fully supported | Any modern distribution |
| **macOS (Apple Silicon)** | Development | Works via Docker Desktop or Podman |
| **Windows WSL2** | Development | Works via Docker Desktop |

### Resource Usage (Typical)

| Component | Memory | Disk | CPU (idle) |
|-----------|--------|------|------------|
| PostgreSQL | 200-500MB | Variable | <1% |
| Backend API | 100-200MB | ~200MB image | <1% |
| Web UI | 50-100MB | ~100MB image | <1% |
| **Total** | ~500MB-1GB | ~500MB + data | <5% |

During email processing (with AI classification), CPU usage will spike temporarily as embeddings are generated.

## Prerequisites

- Docker or Podman with Compose support
- PostgreSQL 16+ with pgvector extension (included in deployment)
- IMAP email account credentials
- OpenAI API key (or Azure OpenAI credentials)

## Minimal Configuration

To get mail-done running with basic functionality, you need only:

### Required Environment Variables

```bash
# Database (auto-generated by deploy scripts)
POSTGRES_PASSWORD=<generated>
DB_ENCRYPTION_KEY=<generated>

# Email account (see provider-specific guides below)
IMAP_USERNAME_WORK=your.email@example.com
IMAP_PASSWORD_WORK=your-app-password  # or OAUTH2_REFRESH_TOKEN_WORK for OAuth2

# LLM for classification (see LLM_CONFIGURATION.md for Azure/multi-provider)
OPENAI_API_KEY=sk-...
```

### Required Config File

Only `config/accounts.yaml` is strictly required:

```yaml
accounts:
  work:
    display_name: "Work Email"
    imap:
      host: imap.example.com
      port: 993
      use_ssl: true
settings:
  default_account: work
```

> **Provider-Specific Setup:**
> - **Gmail / Google Workspace**: Requires App Password. See [Gmail Setup](GMAIL_SETUP.md)
> - **Microsoft 365 / Outlook**: Requires OAuth2. See [Outlook OAuth2](OUTLOOK_OAUTH2.md)

### Optional Config Files

| File | Purpose | Default Without It |
|------|---------|-------------------|
| `vip_senders.yaml` | Priority senders | No VIP detection |
| `classification_rules.yaml` | Rule-based sorting | AI classification only |
| `ai_category_actions.yaml` | Actions per category | No automatic folder moves |

> **Tip:** Start with minimal config, add files as needed.

---

## ⚠️ Critical: Backup Your Encryption Key

The `DB_ENCRYPTION_KEY` encrypts sensitive email data. **If lost, encrypted data is unrecoverable.**

After deployment, immediately backup:

```bash
# Save encryption key securely
grep DB_ENCRYPTION_KEY .env > ~/backup/mail-done-key.txt
chmod 600 ~/backup/mail-done-key.txt
```

Store this backup in:
- A password manager
- Encrypted external storage
- NOT the same location as your deployment

---

## Quick Start

### 1. Clone the Repository

```bash
# Replace with your repository URL
git clone https://github.com/YOUR-ORG/mail-done.git
cd mail-done
```

> **Note:** Replace `YOUR-ORG` with your GitHub organization or username.

### 2. Configure Environment

```bash
# Copy example environment file
cp .env.example .env

# Edit with your credentials
vim .env
```

Required environment variables:

```bash
# Database (auto-generated if using deploy.sh)
POSTGRES_PASSWORD=<secure-password>
DB_ENCRYPTION_KEY=<fernet-key>

# IMAP Credentials
IMAP_HOST=imap.example.com
IMAP_PORT=993
IMAP_USERNAME=your-email@example.com
IMAP_PASSWORD=your-password

# LLM Provider (choose one)
OPENAI_API_KEY=sk-...

# Or Azure OpenAI
AZURE_OPENAI_ENDPOINT=https://your-instance.openai.azure.com
AZURE_OPENAI_API_KEY=your-key
AZURE_OPENAI_DEPLOYMENT=gpt-4o
```

### 3. Deploy

**Using Docker:**
```bash
./deploy/deploy.sh
```

**Using Podman (e.g., Raspberry Pi):**
```bash
./deploy/deploy.sh --pi
```

The deployment script will:
1. Generate secure passwords if `.env` doesn't exist
2. Build and start all containers
3. Run database migrations
4. Test the health endpoint

## Deployment Options

### Standard Docker Deployment

Uses `deploy/docker-compose.yml`:

```bash
docker compose -f deploy/docker-compose.yml up -d
```

Services:
- **db**: PostgreSQL 16 with pgvector
- **api**: FastAPI backend on port 8000

### Raspberry Pi / ARM64 Deployment

See the dedicated [Raspberry Pi Deployment Guide](#raspberry-pi-deployment-guide) below for complete instructions.

## Services

### Backend API (port 8000)

The FastAPI backend provides:
- REST API for email access
- Semantic search endpoints
- Statistics and cost tracking
- Health monitoring

Test the API:
```bash
curl http://localhost:8000/health
```

For full API documentation, see [docs/API.md](API.md) or visit `http://localhost:8000/docs`.

### Web UI (port 8080)

Optional lightweight web interface for:
- Semantic email search
- Inbox processing triggers
- System statistics

**Docker deployment:**
```bash
cd web-ui
docker compose up -d
```

**Podman deployment (Raspberry Pi):**
```bash
cd ~/mail-done/web-ui

# Create .env with API key (must match backend API_KEY)
API_KEY=$(grep "^API_KEY=" ../.env | cut -d= -f2)
cat > .env << EOF
# Backend API connection
BACKEND_API_URL=http://localhost:8000

# Web UI server port
WEB_UI_PORT=8080

# API key for backend authentication (MUST match backend's API_KEY)
API_KEY=$API_KEY

# External URL for OAuth callbacks (use hostname/IP accessible from browser)
WEB_UI_BASE_URL=http://$(hostname):8080

# Disable authentication for local/trusted network access
# Set to 'false' and configure Google OAuth for public access
AUTH_DISABLED=true
EOF

# Build the image
podman build -t mail-done-webui .

# Run the container
podman run -d \
    --name mail-done-webui \
    --network host \
    --restart unless-stopped \
    --env-file .env \
    localhost/mail-done-webui:latest

# Verify it's running
curl http://localhost:8080/health
# Expected: {"status": "healthy"}
```

> **Important:** The `API_KEY` in web-ui `.env` must exactly match the `API_KEY` in the backend `.env`. The web-ui uses this key to authenticate requests to the backend API.

### PostgreSQL Database

PostgreSQL 16 with extensions:
- **pgvector**: Vector similarity search
- **uuid-ossp**: UUID generation
- **pg_trgm**: Text search

Connection string:
```
postgresql://postgres:$POSTGRES_PASSWORD@localhost:5432/email_processor
```

For schema details and direct queries, see [docs/DATABASE.md](DATABASE.md).

### Database Image Options

Choose the appropriate PostgreSQL image based on your needs:

| Image | Size | Extensions | Use Case |
|-------|------|------------|----------|
| `pgvector/pgvector:pg16` | 541 MB | vector, pg_trgm, uuid-ossp | Basic deployment, limited disk space |
| `timescale/timescaledb-ha:pg16` | 5.4 GB | vector, vectorscale, timescaledb, pg_trgm, uuid-ossp | Full features, production use |

**When to use each:**

- **pgvector/pgvector:pg16** (default): Suitable for most deployments. Smaller image, faster to pull.

- **timescale/timescaledb-ha:pg16**: Required if:
  - Migrations fail with `extension "vectorscale" is not available`
  - You want DiskANN indexes for faster vector search at scale
  - You need TimescaleDB for time-series analytics

**Switching images:**

```bash
# Stop and remove existing database
podman stop mail-done-db && podman rm mail-done-db
podman volume rm mail-done-db-data

# Start with timescaledb-ha (note different data path)
podman run -d \
    --name mail-done-db \
    --network host \
    --restart unless-stopped \
    -e POSTGRES_USER=postgres \
    -e POSTGRES_PASSWORD="$POSTGRES_PASSWORD" \
    -e POSTGRES_DB=email_processor \
    -v mail-done-db-data:/home/postgres/pgdata/data \
    docker.io/timescale/timescaledb-ha:pg16
```

> **Note:** The data volume path differs between images:
> - pgvector: `/var/lib/postgresql/data`
> - timescaledb-ha: `/home/postgres/pgdata/data`

## Environment Variables Reference

### Required

| Variable | Description |
|----------|-------------|
| `POSTGRES_PASSWORD` | Database password |
| `DB_ENCRYPTION_KEY` | Fernet key for field-level encryption |
| `IMAP_HOST` | IMAP server hostname |
| `IMAP_PORT` | IMAP server port (usually 993) |
| `IMAP_USERNAME` | Email address |
| `IMAP_PASSWORD` | Email password or app password |
| `OPENAI_API_KEY` | OpenAI API key (or use Azure) |

### Optional

| Variable | Description | Default |
|----------|-------------|---------|
| `API_PORT` | Backend API port | 8000 |
| `POSTGRES_PORT` | Database port | 5432 |
| `POSTGRES_USER` | Database user | postgres |
| `POSTGRES_DB` | Database name | email_processor |
| `DRY_RUN` | Disable IMAP modifications | false |
| `CONFIG_DIR` | Custom config directory overlay | ./config |
| `PROMPTS_DIR` | Custom prompts directory overlay | ./backend/core/ai/prompts |

### Azure OpenAI (alternative to OpenAI)

| Variable | Description |
|----------|-------------|
| `AZURE_OPENAI_ENDPOINT` | Azure OpenAI endpoint URL |
| `AZURE_OPENAI_API_KEY` | Azure OpenAI API key |
| `AZURE_OPENAI_DEPLOYMENT` | Deployment name (e.g., gpt-4o) |

## Private Configuration Overlay

### Why Use a Private Overlay?

The mail-done repository contains **example** config files (`*.example.yaml`) that are safe to share publicly. However, your actual configuration contains **private information**:

| What's Private | Why It Matters |
|----------------|----------------|
| VIP sender lists | Reveals your important contacts |
| Email accounts | Contains your IMAP server hostnames |
| Classification rules | Shows your organizational structure |
| Custom prompts | May contain proprietary instructions |

**Solution:** Keep your private configs in a **separate private repository** that you control.

### Benefits of Using an Overlay

1. **Security**: Private data stays in a private repo, not in the public mail-done repo
2. **Portability**: Clone your config to any machine (laptop, server, Pi)
3. **Versioning**: Track changes to your rules over time with git
4. **Consistency**: Same config on local machine and deployed server
5. **Updates**: Update mail-done without losing your customizations

> **⚠️ Important:** The config overlay must exist on **both** your local machine (for running `process_inbox.py`) **and** on the deployment target (Pi/server). Otherwise, local processing and the deployed API will use different configurations.

### How It Works

```
Local machine                    Raspberry Pi / Server
─────────────────                ─────────────────────
~/mail-done-config/      ──sync──>   ~/mail-done-config/
       │                                    │
       ▼                                    ▼
process_inbox.py               FastAPI (deployed)
(uses CONFIG_DIR)              (mounts CONFIG_DIR)
```

**Both** use the same config, ensuring consistent behavior.

### Step 1: Generate Config Overlay

Use the provided script to create a config overlay:

```bash
# Generate recommended config overlay
./scripts/init-config-overlay.sh ~/mail-done-config

# Or minimal (just accounts + VIP senders)
./scripts/init-config-overlay.sh ~/mail-done-config --minimal

# Or full (all config files)
./scripts/init-config-overlay.sh ~/mail-done-config --full
```

The script will:
1. Create the directory structure
2. Copy example configs as starting points
3. Initialize a git repository
4. Create a README with usage instructions

### Step 2: Customize Your Configs

```bash
cd ~/mail-done-config

# Required: Configure your email accounts
vim accounts.yaml

# Recommended: Add your VIP senders
vim vip_senders.yaml

# Optional: Customize classification rules
vim classification_rules.yaml
```

**Minimum required:** `accounts.yaml` with your IMAP server settings.

### Step 3: Configure Local Environment

Add to your **local** `.env` or shell profile:

```bash
export CONFIG_DIR=~/mail-done-config
export PROMPTS_DIR=~/mail-done-config/prompts  # Optional
```

Now `process_inbox.py` locally will use your private config.

### Step 4: Deploy Config to Pi/Server

**Option A: Git clone (recommended)**

```bash
# On the Pi/server
cd ~
git clone git@github.com:you/mail-done-config.git mail-done-config
```

**Option B: rsync**

```bash
# From local machine
rsync -avz ~/mail-done-config/ pi@your-pi:~/mail-done-config/
```

### Step 5: Configure Deployment to Use Overlay

Add to `.env` on the Pi (in the mail-done directory):

```bash
CONFIG_DIR=/home/pi/mail-done-config
```

The deployment script (`deploy-pi.sh`) automatically:
1. Checks if `CONFIG_DIR` is set in `.env`
2. Verifies the directory exists
3. Mounts it into the container

### Keeping Configs in Sync

When you update your private config locally:

```bash
# Local: commit and push
cd ~/mail-done-config
git add -A && git commit -m "Update VIP list"
git push

# On Pi: pull updates and restart
ssh pi@your-pi
cd ~/mail-done-config && git pull
cd ~/mail-done && ./deploy/deploy-pi.sh --stop && ./deploy/deploy-pi.sh
```

### Syncing Credentials for Local Use

For local tools (MCP server, `process_inbox.py`) to connect to your deployed API, copy the generated credentials from the Pi to your local `.env`:

```bash
# Copy credentials from Pi to local .env
ssh pi@your-pi 'grep -E "^(API_KEY|DB_ENCRYPTION_KEY)=" ~/mail-done/.env' >> ~/mail-done/.env

# Or manually add to your local .env:
API_KEY=<from-pi>
DB_ENCRYPTION_KEY=<from-pi>
```

**Why these are needed locally:**

| Credential | Local Use Case |
|------------|----------------|
| `API_KEY` | MCP server, web-ui, any API client |
| `DB_ENCRYPTION_KEY` | `process_inbox.py` if connecting to remote database |

**For MCP server configuration** (`~/.claude/claude_code_config.json`):
```json
{
  "mcpServers": {
    "email-search": {
      "command": "/path/to/mail-done/run_mcp_server.sh",
      "env": {
        "BACKEND_API_KEY": "<your-API_KEY>",
        "EMAIL_API_URL": "http://your-pi:8000"
      }
    }
  }
}
```

### Overlay Directory Structure

```
mail-done-config/               # Your private repo
├── accounts.yaml               # Email server settings (REQUIRED)
├── vip_senders.yaml            # Priority senders
├── classification_rules.yaml   # Rule-based sorting
├── ai_category_actions.yaml    # Folder moves per category
├── categories.yaml             # Category definitions
└── prompts/                    # Custom AI prompts (optional)
    └── classifier_system.txt
```

### Overlay Behavior

- Files in `CONFIG_DIR` **replace** the defaults completely
- If a file is missing from overlay, the default from `config/` is used
- No merging occurs - it's all-or-nothing per file

### Verification

Check which config is being used:

```bash
# On Pi - check what's mounted
podman exec mail-done-api ls -la /app/config/

# Check logs for config path
podman logs mail-done-api 2>&1 | grep -i config
```

## Monitoring

### Health Check

```bash
curl http://localhost:8000/health
```

Response:
```json
{
  "status": "healthy",
  "database": "connected",
  "version": "2.0.0"
}
```

### View Logs

```bash
# Docker
docker compose -f deploy/docker-compose.yml logs -f api

# Podman
podman-compose -f deploy/docker-compose.pi.yml logs -f api
```

### Service Status

```bash
docker compose -f deploy/docker-compose.yml ps
```

## Maintenance

### Restart Services

```bash
docker compose -f deploy/docker-compose.yml restart api
```

### Update Deployment

```bash
git pull
docker compose -f deploy/docker-compose.yml up -d --build
```

### Database Backup

```bash
docker exec mail-done-db pg_dump -U postgres email_processor > backup.sql
```

### Database Restore

```bash
docker exec -i mail-done-db psql -U postgres email_processor < backup.sql
```

## Troubleshooting

### API not responding

1. Check container status: `docker compose ps`
2. Check logs: `docker compose logs api`
3. Verify database is healthy: `docker compose logs db`

### Database connection failed

1. Ensure PostgreSQL is running
2. Check `DATABASE_URL` format
3. Verify network connectivity between containers

### IMAP connection failed

1. Verify credentials in `.env`
2. Check if app password is needed (Gmail, etc.)
3. Test manually: `openssl s_client -connect imap.example.com:993`

### Migrations failed

Run migrations manually:
```bash
docker exec mail-done-api poetry run alembic upgrade head
```

## Security Notes

- Change default passwords in production
- Use HTTPS reverse proxy (nginx, Caddy) for external access
- Use a VPN for secure remote access
- Enable rate limiting in production
- Keep `DB_ENCRYPTION_KEY` secure and backed up (see warning above)

## Log Rotation

Prevent logs from filling disk:

**Docker Compose** - Add to `docker-compose.yml`:
```yaml
services:
  api:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
```

**Podman** - Use log options:
```bash
podman run -d \
    --log-opt max-size=10m \
    --log-opt max-file=3 \
    ...
```

## HTTPS with Caddy (Recommended)

For secure external access, use Caddy as a reverse proxy:

```bash
# Install Caddy
sudo apt install caddy

# Configure /etc/caddy/Caddyfile
mail-done.yourdomain.com {
    reverse_proxy localhost:8000
}

# Start Caddy (auto-provisions Let's Encrypt certificates)
sudo systemctl enable --now caddy
```

Access via: `https://mail-done.yourdomain.com`

---

## Raspberry Pi Deployment Guide

This section provides complete, step-by-step instructions for deploying mail-done on a Raspberry Pi (tested on Pi 4 with 4GB RAM running Raspberry Pi OS Bookworm).

### System Requirements

**Hardware:**
- Raspberry Pi 4 (4GB+ RAM recommended)
- 16GB+ SD card or USB SSD (SSD recommended for faster builds)
- Network connection

**Software:**
- Raspberry Pi OS Bookworm (64-bit) or Debian 12+
- Python 3.11+

### Step 1: Install System Packages

```bash
# Update system
sudo apt-get update && sudo apt-get upgrade -y

# Install required packages
sudo apt-get install -y \
    podman \
    podman-compose \
    git \
    openssl \
    python3 \
    python3-cryptography \
    curl

# Verify installations
podman --version      # Should be 4.x+
podman-compose --version
python3 --version     # Should be 3.11+
```

### Step 2: Clone the Repository

```bash
cd ~

# Option A: Clone via HTTPS (no SSH key required)
git clone https://github.com/ratsch/mail-done.git mail-done

# Option B: Clone via SSH (requires SSH key configured)
git clone git@github.com:ratsch/mail-done.git mail-done

cd mail-done
```

**Note:** If you get `Host key verification failed` with SSH, use the HTTPS URL instead.

### Step 3: Configure Environment

```bash
# Copy example environment file
cp .env.example .env

# Generate secure credentials
POSTGRES_PASSWORD=$(openssl rand -hex 16)
DB_ENCRYPTION_KEY=$(python3 -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())")
API_KEY=$(openssl rand -hex 24)

# Update .env with generated values
sed -i "s|^POSTGRES_PASSWORD=.*|POSTGRES_PASSWORD=$POSTGRES_PASSWORD|" .env
sed -i "s|^DB_ENCRYPTION_KEY=.*|DB_ENCRYPTION_KEY=$DB_ENCRYPTION_KEY|" .env
sed -i "s|^API_KEY=.*|API_KEY=$API_KEY|" .env

# Save credentials for reference
echo "Generated credentials:"
echo "  POSTGRES_PASSWORD: $POSTGRES_PASSWORD"
echo "  API_KEY: $API_KEY"
echo "  DB_ENCRYPTION_KEY: (saved in .env)"
```

**Edit `.env` to add your credentials:**

```bash
vim .env
```

Required settings:
```bash
# LLM Provider (choose one)
OPENAI_API_KEY=sk-...

# Or Azure OpenAI
AZURE_OPENAI_ENDPOINT=https://your-instance.openai.azure.com
AZURE_OPENAI_API_KEY=your-key
AZURE_OPENAI_DEPLOYMENT=gpt-4o

# IMAP credentials (optional - for email processing)
IMAP_HOST_WORK=imap.example.com
IMAP_PORT_WORK=993
IMAP_USERNAME_WORK=your-email@example.com
IMAP_PASSWORD_WORK=your-password
```

### Step 4: Setup Config Files

```bash
# Copy all config examples to active configs
for example in config/*.example.yaml; do
    target="${example%.example.yaml}.yaml"
    [ -f "$target" ] || cp "$example" "$target"
done

# Optionally customize configs
ls config/*.yaml
```

### Step 5: Deploy Using the Script

The easiest method uses the provided deployment script:

```bash
./deploy/deploy-pi.sh
```

The script will:
1. Check prerequisites (podman, podman-compose, openssl, python3)
2. Generate credentials if `.env` doesn't exist
3. Copy config examples to active configs
4. Build the API container image
5. Start PostgreSQL with pgvector
6. Start the API container
7. Wait for services to be healthy

**Script options:**
```bash
./deploy/deploy-pi.sh           # Full deployment
./deploy/deploy-pi.sh --status  # Show service status
./deploy/deploy-pi.sh --logs    # View container logs
./deploy/deploy-pi.sh --stop    # Stop all services
./deploy/deploy-pi.sh --clean   # Remove containers, volumes, and configs
```

### Step 6: Database Migrations

The API container automatically runs database migrations on startup. For manual control:

```bash
# Check current migration status
podman exec mail-done-api alembic current

# Run pending migrations manually
podman exec mail-done-api alembic upgrade head

# For existing databases with tables already created, stamp without running:
podman exec mail-done-api alembic stamp head
```

**Migration Flow:**
1. Docker `init-db.sql` creates PostgreSQL extensions (pgvector, uuid-ossp, pg_trgm)
2. API container runs `alembic upgrade head` on startup
3. Alembic creates all tables and indexes if missing

**For existing production databases** that already have all tables (like nvme-pi):
```bash
# Mark as current without running migrations
./scripts/db_migrate.sh --stamp
```

### Step 7: Verify Deployment

```bash
# Check container status
podman ps --filter "name=mail-done"

# Test health endpoint
curl http://localhost:8000/health

# Test API info
curl http://localhost:8000/

# Test with API key
API_KEY=$(grep "^API_KEY=" .env | cut -d= -f2)
curl -H "X-API-Key: $API_KEY" http://localhost:8000/api/emails?limit=5
```

Expected health response:
```json
{
  "status": "healthy",
  "version": "2.0.0",
  "database": "connected",
  "checks": {"database": "ok"}
}
```

**Comprehensive Functional Test:**

Use the provided test script to verify all components:

```bash
# Test local deployment
python3 deploy/test-deployment.py

# Test remote deployment
python3 deploy/test-deployment.py http://hostname:8000
```

Expected output:
```
============================================================
  Mail-Done Deployment Tests
  Target: http://localhost:8000
============================================================

Core Health Checks:
✓ Health endpoint accessible
✓ Status is healthy
✓ Database connected
✓ Database health check passed

API Information:
✓ Root endpoint accessible
✓ Version info present
✓ Features listed
  Version: 2.0.0

API Documentation:
✓ OpenAPI spec accessible
✓ API has endpoints defined (91 found)

Authentication Enforcement:
✓ Stats requires auth
✓ Emails requires auth
✓ Admin endpoints require auth
✓ Applications requires auth

============================================================
  All 12 tests passed!
  Deployment is working correctly.
============================================================
```

### Step 8: Run Tests (Recommended)

#### Functional Deployment Tests

Run the deployment test script to verify all components:

```bash
# From the mail-done directory
python3 deploy/test-deployment.py http://localhost:8000

# Or test from another machine
python3 deploy/test-deployment.py http://your-pi:8000
```

Expected output:
```
============================================================
  Mail-Done Deployment Tests
============================================================
✓ Health endpoint accessible
✓ Database connected
✓ API has endpoints defined (91 found)
✓ Authentication enforcement working
============================================================
  All 13 tests passed!
============================================================
```

#### Unit Tests

> **Note:** The production container image is built with `--only main` to reduce size, so pytest and other dev dependencies are not included. Run unit tests locally or from a dev environment.

**Run locally (not in container):**
```bash
# From your development machine with poetry installed
cd mail-done
poetry run pytest backend/tests/unit/ -v
```

**If you need tests in the container**, rebuild with dev dependencies:
```bash
# Modify Dockerfile: change "poetry install --only main" to "poetry install"
# Then rebuild
podman build -t mail-done-api-dev .
```

If tests fail, check:
1. Database connection: `podman logs mail-done-db`
2. Environment variables: `podman exec mail-done-api env | grep DATABASE`
3. Config files: `podman exec mail-done-api ls -la /app/config/`

### Step 9: Process Your First Emails

With deployment verified, process some emails:

```bash
# Preview mode first (no changes made)
podman exec mail-done-api python3 process_inbox.py --dry-run --limit 10

# Process new emails
podman exec mail-done-api python3 process_inbox.py --new-only --limit 50
```

For detailed processing options, see [docs/PROCESS_INBOX.md](PROCESS_INBOX.md).

### Step 10: Set Up Automation (Optional)

For automatic email processing, add a cron job:

```bash
# Edit crontab
crontab -e

# Process new emails every 15 minutes
*/15 * * * * podman exec mail-done-api python3 process_inbox.py --new-only >> /var/log/mail-done-process.log 2>&1
```

Or use systemd timer (see [PROCESS_INBOX.md#automation](PROCESS_INBOX.md#automation)).

### Step 11: Configure MCP Server (Optional)

To enable email search in Claude or Cursor:

1. **Verify MCP server works:**
   ```bash
   cd ~/mail-done
   ./run_mcp_server.sh
   # Press Ctrl+C after confirming it starts
   ```

2. **Configure your AI assistant:**

   For Claude Code (`~/.claude/claude_code_config.json`):
   ```json
   {
     "mcpServers": {
       "email-search": {
         "command": "/home/user/mail-done/run_mcp_server.sh",
         "env": {
           "BACKEND_API_KEY": "<your-API_KEY>",
           "EMAIL_API_URL": "http://your-pi:8000"
         }
       }
     }
   }
   ```

For complete MCP setup, see [docs/MCP.md](MCP.md).

---

### Manual Deployment (Alternative)

If you prefer manual control or the script doesn't work:

```bash
cd ~/mail-done

# Source environment
set -a && source .env && set +a

# Build the API image
podman-compose -f deploy/docker-compose.pi.yml build

# Create database volume
podman volume create mail-done-db-data

# Start PostgreSQL
podman run -d \
    --name mail-done-db \
    --network host \
    --restart unless-stopped \
    -e POSTGRES_USER="${POSTGRES_USER:-postgres}" \
    -e POSTGRES_PASSWORD="$POSTGRES_PASSWORD" \
    -e POSTGRES_DB="${POSTGRES_DB:-email_processor}" \
    -e PGPORT="${POSTGRES_PORT:-5432}" \
    -v mail-done-db-data:/var/lib/postgresql/data \
    -v "$PWD/deploy/init-db.sql:/docker-entrypoint-initdb.d/init.sql:ro" \
    docker.io/pgvector/pgvector:pg16

# Wait for database
sleep 10
podman exec mail-done-db pg_isready -U postgres

# Start API
podman run -d \
    --name mail-done-api \
    --network host \
    --restart unless-stopped \
    --env-file .env \
    -e PORT="${API_PORT:-8000}" \
    -e DATABASE_URL="postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD}@localhost:${POSTGRES_PORT:-5432}/${POSTGRES_DB:-email_processor}" \
    -v "$PWD/config:/app/config:ro" \
    localhost/deploy_api:latest

# Run migrations (creates tables/indexes)
podman exec mail-done-api alembic upgrade head
```

### Raspberry Pi Troubleshooting

#### Build Fails with slirp4netns Error

**Problem:** `podman build` fails during `poetry install` with:
```
error running container: did not get container start message from parent: EOF
Error: building at STEP "RUN poetry install...": slirp4netns failed
```

**Cause:** Network namespace issue with rootless podman on some Pi configurations.

**Solutions:**

1. **Transfer a pre-built image from another host** (recommended):
   ```bash
   # On a working host (e.g., another Pi or x86 machine with working builds)
   podman save localhost/mail-done_api:latest | gzip > /tmp/mail-done-api.tar.gz

   # Transfer to target Pi
   scp /tmp/mail-done-api.tar.gz pi@target-pi:/tmp/

   # On target Pi - import the image
   gunzip -c /tmp/mail-done-api.tar.gz | podman load

   # Verify
   podman images | grep mail-done
   ```

2. **Try building as root** (less recommended):
   ```bash
   sudo podman build -t mail-done-api .
   ```

3. **Update slirp4netns**:
   ```bash
   sudo apt update && sudo apt install -y slirp4netns
   ```

#### Migration Fails with Extension Error

**Problem:** API container fails on startup with:
```
extension "vectorscale" is not available
```

**Cause:** The standard `pgvector/pgvector:pg16` image doesn't include the vectorscale extension.

**Solutions:**

1. **Use timescaledb-ha image** (see [Database Image Options](#database-image-options)):
   ```bash
   # Replace pgvector with timescaledb-ha
   podman run -d --name mail-done-db ... docker.io/timescale/timescaledb-ha:pg16
   ```

2. **Or import schema manually and skip migrations** (see [Manual Schema Setup](#manual-schema-setup-skip-migrations)).

#### Migration Fails with SQLAlchemy Error

**Problem:** Migration crashes with:
```
TypeError: sqlalchemy.cyextension.immutabledict.immutabledict is not a sequence
```

**Cause:** Version mismatch between SQLAlchemy/Alembic in the container vs. what migrations expect.

**Solution:** Skip automatic migrations and set up the schema manually:

1. Import schema from a working database (see [Manual Schema Setup](#manual-schema-setup-skip-migrations))
2. Start API without running migrations

---

### Manual Schema Setup (Skip Migrations)

If migrations fail (due to extension issues, version mismatches, or compatibility problems), you can set up the database schema manually:

#### Option 1: Import from Production Database

```bash
# On production host - export schema only (no data)
podman exec mail-done-db pg_dump -U postgres -d email_processor \
    --schema-only --no-owner --no-privileges > /tmp/schema.sql

# Transfer to new host
scp production-host:/tmp/schema.sql /tmp/

# Import to new database
cat /tmp/schema.sql | podman exec -i mail-done-db psql -U postgres -d email_processor

# Check tables were created
podman exec mail-done-db psql -U postgres -d email_processor -c '\dt'
```

#### Option 2: Start API Without Migrations

Override the container startup command to skip the `alembic upgrade head` step:

```bash
podman run -d \
    --name mail-done-api \
    --network host \
    --restart unless-stopped \
    --env-file .env \
    -e PORT=8000 \
    -e DATABASE_URL="postgresql://postgres:$POSTGRES_PASSWORD@localhost:5432/email_processor" \
    -v "$PWD/config:/app/config:ro" \
    localhost/mail-done_api:latest \
    sh -c 'poetry run uvicorn backend.api.main:app --host 0.0.0.0 --port ${PORT:-8000}'
```

#### Stamp Alembic Version

After manually creating the schema, mark migrations as applied:

```bash
# Check current alembic version on production
podman exec mail-done-db psql -U postgres -d email_processor \
    -c "SELECT * FROM alembic_version;"

# Insert the same version on new database
podman exec mail-done-db psql -U postgres -d email_processor \
    -c "INSERT INTO alembic_version (version_num) VALUES ('001_initial');"
```

---

### Verify Deployment

After deployment, verify all components are working:

```bash
# 1. Check all containers are running
podman ps --filter "name=mail-done"

# Expected: mail-done-db, mail-done-api, mail-done-webui (if deployed)

# 2. Test API health
curl -s http://localhost:8000/health | python3 -m json.tool

# Expected: {"status": "healthy", "database": "connected", ...}

# 3. Test authenticated endpoint
API_KEY=$(grep "^API_KEY=" .env | cut -d= -f2)
curl -s -H "X-API-Key: $API_KEY" http://localhost:8000/api/stats | python3 -m json.tool

# 4. Test web-ui (if deployed)
curl -s http://localhost:8080/health

# 5. Check database extensions
podman exec mail-done-db psql -U postgres -d email_processor -c '\dx'

# Expected: vector, pg_trgm, uuid-ossp (and vectorscale if using timescaledb-ha)

# 6. Check tables exist
podman exec mail-done-db psql -U postgres -d email_processor -c '\dt' | head -20

# Expected: ~24 tables including emails, email_metadata, classifications, etc.

# 7. Run functional test suite
python3 deploy/test-deployment.py http://localhost:8000
```

---

#### Slow Container Builds

**Problem:** STEP 9/11 COPY takes 20+ minutes

**Cause:** Large files (logs, data directories) being copied into the container.

**Solution:** Ensure `.dockerignore` exists and excludes large directories:
```bash
cat .dockerignore | grep -E "email-processor|venv|LOG"
```

If missing, the key exclusions are:
```
email-processor/
venv/
.venv/
LOG_imapsync/
*.log
```

#### Network Mode Error

**Problem:** `Error: cannot set multiple networks without bridge network mode, selected mode host`

**Cause:** Bug in podman-compose with host networking.

**Solution:** The deploy script uses direct `podman run` commands to bypass this. If using podman-compose directly, this error can be ignored if containers start anyway.

#### Registry Resolution Error

**Problem:** `short-name "pgvector/pgvector:pg16" did not resolve to an alias and no unqualified-search registries are defined`

**Cause:** Podman on some systems doesn't have Docker Hub configured as a default registry.

**Solution:** The deploy script now uses full image paths (`docker.io/pgvector/pgvector:pg16`). If you encounter this with other images, use the full path format: `docker.io/image:tag`

Alternatively, configure registries in `/etc/containers/registries.conf`:
```ini
[registries.search]
registries = ['docker.io']
```

#### Memory Cgroups Error

**Problem:** `crun: opening file 'memory.max' for writing: No such file or directory`

**Cause:** cgroups v2 memory controller not fully enabled.

**Solution:** Either:
1. Don't use memory limits (the deploy script already handles this)
2. Or enable cgroups v2 memory controller:
   ```bash
   # Add to /boot/cmdline.txt (Pi OS) or /boot/firmware/cmdline.txt
   cgroup_enable=memory cgroup_memory=1
   # Reboot
   sudo reboot
   ```

#### Database Tables Don't Exist

**Problem:** `relation "emails" does not exist`

**Cause:** Database schema not initialized.

**Solution:** Run migrations:
```bash
podman exec mail-done-api alembic upgrade head
```

For existing databases that already have tables but no migration tracking:
```bash
podman exec mail-done-api alembic stamp head
```

#### Container Keeps Restarting

**Problem:** API container restarts in a loop

**Solution:** Check logs for the actual error:
```bash
podman logs mail-done-api --tail 50
```

Common causes:
- Missing environment variables (check `.env`)
- Database not ready (wait longer, or restart API)
- Invalid config files (check YAML syntax)

### Pi-Specific Performance Notes

1. **First build on fresh system:** Takes 10-15 minutes as it downloads base images and installs all dependencies. Poetry installs ~110 packages.

2. **Subsequent builds:** With Docker cache, builds complete in ~30 seconds (only COPY step runs).

3. **SD card vs SSD:** USB SSD dramatically improves build times and container I/O.

4. **Memory:** With 4GB RAM, both containers run fine. PostgreSQL will use available memory for caching.

5. **Image pulls:** First deployment downloads ~500MB of container images (python:3.11-slim, pgvector/pgvector:pg16).

4. **CPU:** Container builds are CPU-intensive. The Pi 4 handles this but it takes time.

### Systemd Service (Optional)

To auto-start on boot, create a systemd service:

```bash
# Copy the service file
sudo cp deploy/mail-done.service /etc/systemd/system/

# Edit if needed (check paths)
sudo vim /etc/systemd/system/mail-done.service

# Enable and start
sudo systemctl daemon-reload
sudo systemctl enable mail-done
sudo systemctl start mail-done

# Check status
sudo systemctl status mail-done
```

### Updating the Deployment

```bash
cd ~/mail-done

# Stop services
./deploy/deploy-pi.sh --stop

# Pull updates
git pull

# Rebuild and restart
./deploy/deploy-pi.sh
```

### Complete Removal

To completely remove the deployment:

```bash
# Stop and remove everything
./deploy/deploy-pi.sh --clean

# Remove the .env file (optional - contains your credentials)
rm .env

# Remove images (optional)
podman rmi localhost/deploy_api pgvector/pgvector:pg16
```

### Authentication Configuration

mail-done uses multiple authentication methods depending on the endpoint:

#### 1. API Key Authentication (Basic API Access)

Most `/api/*` endpoints use simple API key authentication.

**Setup:**
1. The API key is auto-generated during deployment (saved in `.env`)
2. Use the `X-API-Key` header for requests

**Example:**
```bash
# Get your API key
API_KEY=$(grep "^API_KEY=" .env | cut -d= -f2)

# Make authenticated request
curl -H "X-API-Key: $API_KEY" http://localhost:8000/api/emails
```

#### 2. Signed Request Authentication (Secure Client Access)

For more secure access (scripts, automation), use Ed25519 signed requests.

**Setup:**

1. Generate a keypair:
```bash
python3 -c "
from cryptography.hazmat.primitives.asymmetric.ed25519 import Ed25519PrivateKey
import base64

pk = Ed25519PrivateKey.generate()
private_key = base64.b64encode(pk.private_bytes_raw()).decode()
public_key = base64.b64encode(pk.public_key().public_bytes_raw()).decode()

print(f'Private key (keep secret): {private_key}')
print(f'Public key (add to config): {public_key}')
"
```

2. Add the public key to `config/clients.yaml`:
```yaml
clients:
  my-script:
    description: "My automation script"
    public_keys:
      - "YOUR_BASE64_PUBLIC_KEY_HERE"
    scopes:
      - "*"  # Full access, or specific scopes like "emails:read"
    enabled: true
```

3. Use the private key in your scripts to sign requests (see `docs/SECURITY_DESIGN_REQUEST_SIGNING.md`).

#### 3. Admin Panel Authentication (Google OAuth)

The `/admin/*` endpoints require Google OAuth authentication for lab member access.

**Setup:**

1. Create a Google Cloud OAuth 2.0 Client:
   - Go to [Google Cloud Console](https://console.cloud.google.com/)
   - Create or select a project
   - Navigate to APIs & Services > Credentials
   - Create OAuth 2.0 Client ID (Web application)
   - Add authorized redirect URI: `http://localhost:8000/auth/google/callback`

2. Add credentials to `.env`:
```bash
# Google OAuth for Admin Panel
GOOGLE_CLIENT_ID_V0_PORTAL=your-client-id.apps.googleusercontent.com
GOOGLE_CLIENT_SECRET_V0_PORTAL=your-client-secret
GOOGLE_REDIRECT_URI_V0_PORTAL=http://localhost:8000/auth/google/callback

# JWT Configuration
JWT_SECRET=$(openssl rand -hex 32)
JWT_EXPIRATION_HOURS=24
```

3. Create the first admin user directly in the database:
```bash
podman exec mail-done-api python3 -c "
from backend.core.database.connection import init_db, get_session
from backend.core.database.models import LabMember
import uuid

init_db()
session = next(get_session())

admin = LabMember(
    id=uuid.uuid4(),
    email='your-email@example.com',
    name='Admin User',
    role='admin',
    can_review=True,
    is_active=True
)
session.add(admin)
session.commit()
print(f'Created admin user: {admin.email}')
"
```

4. Access the admin panel:
   - Navigate to `http://localhost:8000/admin/`
   - Click "Login with Google"
   - Sign in with the email you registered

**Admin Roles:**
- `admin`: Full access to all admin endpoints
- `reviewer`: Can review applications but not manage users
- `member`: Basic lab member (read-only access)

#### Environment Variables for Authentication

| Variable | Description | Required |
|----------|-------------|----------|
| `API_KEY` | Simple API key for `/api/*` endpoints | Yes |
| `JWT_SECRET` | Secret for signing JWT tokens | For admin panel |
| `JWT_EXPIRATION_HOURS` | JWT token lifetime (default: 24) | No |
| `GOOGLE_CLIENT_ID_V0_PORTAL` | Google OAuth client ID | For admin panel |
| `GOOGLE_CLIENT_SECRET_V0_PORTAL` | Google OAuth client secret | For admin panel |
| `GOOGLE_REDIRECT_URI_V0_PORTAL` | OAuth callback URL | For admin panel |

### API Endpoints Quick Reference

After deployment, these endpoints are available:

| Endpoint | Auth | Description |
|----------|------|-------------|
| `GET /health` | No | Health check |
| `GET /` | No | API info |
| `GET /docs` | No | OpenAPI documentation |
| `GET /api/emails` | API Key | List emails |
| `GET /api/costs/overview` | API Key | Cost analytics |
| `GET /api/debug/config` | API Key | Debug configuration |
| `POST /api/applemail/color` | API Key | Apple Mail color lookup |

Use the API key header: `X-API-Key: <your-api-key>`

Example:
```bash
API_KEY=$(grep "^API_KEY=" .env | cut -d= -f2)
curl -H "X-API-Key: $API_KEY" http://localhost:8000/api/emails?limit=10
```

---

## Related Documentation

After deployment, refer to these guides for next steps:

| Guide | Purpose |
|-------|---------|
| [Email Processing](PROCESS_INBOX.md) | Configure rules, process emails, set up cron automation |
| [MCP Server](MCP.md) | Integrate with Claude Code, Claude Desktop, or Cursor |
| [API Reference](API.md) | Full REST API endpoint documentation |
| [Database Schema](DATABASE.md) | PostgreSQL tables, pgvector, direct queries |
| [Web UI](../web-ui/README.md) | Browser-based email search interface |

### Quick Links

| Question | Answer |
|----------|--------|
| "How do I process emails?" | [PROCESS_INBOX.md](PROCESS_INBOX.md) |
| "How do I search from Claude?" | [MCP.md](MCP.md) |
| "What API endpoints exist?" | [API.md](API.md) or `http://localhost:8000/docs` |
| "How is data stored?" | [DATABASE.md](DATABASE.md) |
| "How do I add VIP senders?" | [PROCESS_INBOX.md#vip_senders](PROCESS_INBOX.md#configvip_sendersyaml) |

### Configuration Files Reference

| File | Required | Purpose |
|------|----------|---------|
| `accounts.yaml` | **Yes** | Email server settings (hosts, ports) |
| `categories.yaml` | No | Email category definitions |
| `vip_senders.yaml` | No | Priority sender list with colors |
| `classification_rules.yaml` | No | Rule-based email sorting |
| `ai_category_actions.yaml` | No | Folder moves per AI category |
| `preprocessing_rules.yaml` | No | Forwarded email detection |
| `clients.yaml` | No | Signed request authentication |
